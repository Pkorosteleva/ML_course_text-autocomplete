{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6d00c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Удален старый файл: ./data/train_cleaned.txt\n",
      "Удален старый файл: ./data/val_cleaned.txt\n",
      "Удален старый файл: ./data/test_cleaned.txt\n",
      "Загружено 500001 строк из файла\n",
      "Train: 399194 samples\n",
      "Val: 49899 samples\n",
      "Test: 49900 samples\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 1: Подготовка данных\n",
    "from src.data_utils import main as data_main\n",
    "data_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb6200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 2: Создание DataLoader'ов\n",
    "from src.next_token_dataset import create_data_loaders\n",
    "train_loader, val_loader, test_loader, vocab = create_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e82ce36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начинаем обучение...\n",
      "Размер словаря: 160609\n",
      "Количество батчей: 6238\n",
      "Устройство: cpu\n",
      "--------------------------------------------------\n",
      "Эпоха 1/5 | Батч 0/6238 | Loss: 11.9827\n",
      "CUDA not available\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ячейка 3: Обучение модели\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlstm_train\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_model\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Polina\\ML_Course\\text-autocomplete\\ML_course_text-autocomplete\\src\\lstm_train.py:120\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Нормализуем loss для accumulation\u001b[39;00m\n\u001b[0;32m    119\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m accumulation_steps\n\u001b[1;32m--> 120\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (batch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    123\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Polina\\ML_Course\\text-autocomplete\\ML_course_text-autocomplete\\venv\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Polina\\ML_Course\\text-autocomplete\\ML_course_text-autocomplete\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Polina\\ML_Course\\text-autocomplete\\ML_course_text-autocomplete\\venv\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Ячейка 3: Обучение модели\n",
    "from src.lstm_train import train_model\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86994299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LSTM Model Predictions ===\n",
      "'I think' -> 'I think cassidy...yum!!!! knoooo...i repeat, cassidy...yum!!!! 30minmeditation broser ill.... broser egg, 45.2790'\n",
      "'The weather is' -> 'The weather is yoyos!...its cassidy...yum!!!! 30minmeditation broser ill.... broser egg, 45.2790 yoyos!...its cassidy...yum!!!!'\n",
      "'I want to' -> 'I want to poli, mombasa ....maine, mainstreams mondays.....i originswolverine. cswk landquot toooooo! broser'\n",
      "'This movie is' -> 'This movie is mondays.....i cswk apes,et mooch cswk landquot that...put broser 1.45b poli,'\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 4: Загрузка и тестирование обученной LSTM модели\n",
    "from src.lstm_model import LSTMLanguageModel\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTMLanguageModel(vocab_size=vocab['vocab_size']).to(device)\n",
    "\n",
    "# ИСПРАВЛЕННАЯ СТРОКА - добавьте map_location\n",
    "model.load_state_dict(torch.load('./models/lstm_model_bs64_accum4.pth', map_location=device))\n",
    "\n",
    "# Тестирование LSTM\n",
    "test_texts = [\"I think\", \"The weather is\", \"I want to\", \"This movie is\"]\n",
    "print(\"=== LSTM Model Predictions ===\")\n",
    "for test_text in test_texts:\n",
    "    prediction = model.predict_next_tokens(test_text, vocab, num_tokens=10)\n",
    "    print(f\"'{test_text}' -> '{prediction}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "132b520c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Использование предобученного трансформера\n",
      "==================================================\n",
      "Загружаем модель distilgpt2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Transformer Model Predictions ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'I think' -> 'this will be an interesting time to look at the'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The weather is' -> 'going to improve.”'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'I want to' -> 'see what he learns. He sees what is out'\n",
      "'This movie is' -> 'about a young man and a woman who have gone'\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 5: Использование предобученного трансформера\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Использование предобученного трансформера\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "from src.transformer_model import TransformerTextGenerator, evaluate_transformer_model\n",
    "\n",
    "# Инициализация трансформера\n",
    "print(\"Загружаем модель distilgpt2...\")\n",
    "transformer_generator = TransformerTextGenerator()\n",
    "\n",
    "# Тестирование трансформера\n",
    "print(\"\\n=== Transformer Model Predictions ===\")\n",
    "for test_text in test_texts:\n",
    "    prediction = transformer_generator.generate_text(test_text, max_length=10)\n",
    "    print(f\"'{test_text}' -> '{prediction}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0063504a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Сравнение моделей и выводы\n",
      "==================================================\n",
      "=== СРАВНЕНИЕ МОДЕЛЕЙ ===\n",
      "Оцениваем LSTM модель...\n",
      "Оцениваем Transformer модель...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['early_stopping']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "РЕЗУЛЬТАТЫ СРАВНЕНИЯ:\n",
      "==================================================\n",
      "LSTM Model:\n",
      "  ROUGE-1 F1: 0.0314\n",
      "  ROUGE-2 F1: 0.0016\n",
      "Transformer Model:\n",
      "  ROUGE-1 F1: 0.0545\n",
      "  ROUGE-2 F1: 0.0009\n",
      "==================================================\n",
      "\n",
      "ПРИМЕРЫ ГЕНЕРАЦИИ LSTM:\n",
      "1. Промпт: 'molly lost her ipod'\n",
      "   Цель: 'touch last night, !'\n",
      "   LSTM: 'molly lost her ipod vent. hex. spurs!!! ramani'\n",
      "\n",
      "2. Промпт: 'day 2 of headache horror, what'\n",
      "   Цель: 'a way to say quotgood morningquot, ugh!'\n",
      "   LSTM: 'day 2 of headache horror, what chan sleeping...even in....im stay? gazillions whatsup? swe.'\n",
      "\n",
      "3. Промпт: 'od on vitamin c! i'\n",
      "   Цель: 'feel like i have a fever..'\n",
      "   LSTM: 'od on vitamin c! i chan vent. crampssssssss u.n., bookmarked. beirut'\n",
      "\n",
      "4. Промпт: 'on our way to parents house to drop of moms'\n",
      "   Цель: 'bithday gift. nice scentrd lotion. wont see her today though'\n",
      "   LSTM: 'on our way to parents house to drop of moms whatsup? swe. minks. activityquot disgraceful. authors bastard!! chan vent. hex.'\n",
      "\n",
      "5. Промпт: 'my q'\n",
      "   Цель: 'key broke'\n",
      "   LSTM: 'my q whatsup? swe.'\n",
      "\n",
      "\n",
      "ПРИМЕРЫ ГЕНЕРАЦИИ TRANSFORMER:\n",
      "1. Промпт: 'molly lost her ipod'\n",
      "   Цель: 'touch last night, !'\n",
      "   Transformer: 'and her phone to'\n",
      "\n",
      "2. Промпт: 'day 2 of headache horror, what'\n",
      "   Цель: 'a way to say quotgood morningquot, ugh!'\n",
      "   Transformer: 'the hell?\n",
      "\n",
      "I have'\n",
      "\n",
      "3. Промпт: 'od on vitamin c! i'\n",
      "   Цель: 'feel like i have a fever..'\n",
      "   Transformer: ''ve been buying vitamins that I'\n",
      "\n",
      "4. Промпт: 'on our way to parents house to drop of moms'\n",
      "   Цель: 'bithday gift. nice scentrd lotion. wont see her today though'\n",
      "   Transformer: '.”\n",
      "\n",
      "And I’m'\n",
      "\n",
      "5. Промпт: 'my q'\n",
      "   Цель: 'key broke'\n",
      "   Transformer: '.p'\n",
      "\n",
      "\n",
      "==================================================\n",
      "ВЫВОДЫ И РЕКОМЕНДАЦИИ:\n",
      "==================================================\n",
      "⚡ Модели показывают сопоставимые результаты\n",
      "Рекомендация: Выбор зависит от конкретных требований:\n",
      "  - Transformer: лучше качество, но больше ресурсов\n",
      "  - LSTM: быстрее, меньше памяти, но может уступать в качестве\n"
     ]
    }
   ],
   "source": [
    "# Ячейка 6: Сравнение моделей по метрикам\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Сравнение моделей и выводы\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "from src.model_comparison import compare_models\n",
    "\n",
    "# Запускаем сравнение\n",
    "compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df06cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 7: Детальный анализ и выводы\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Финальные выводы и рекомендации\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Дополнительные примеры для качественного анализа\n",
    "print(\"\\nДополнительные примеры для сравнения:\")\n",
    "\n",
    "complex_examples = [\n",
    "    \"The future of artificial intelligence\",\n",
    "    \"I believe that climate change\",\n",
    "    \"The best way to learn programming\",\n",
    "    \"In my opinion, the government should\"\n",
    "]\n",
    "\n",
    "print(\"\\nLSTM Predictions:\")\n",
    "for example in complex_examples:\n",
    "    lstm_pred = model.predict_next_tokens(example, vocab, num_tokens=15)\n",
    "    print(f\"  '{example}' -> '{lstm_pred}'\")\n",
    "\n",
    "print(\"\\nTransformer Predictions:\")\n",
    "for example in complex_examples:\n",
    "    transformer_pred = transformer_generator.generate_text(example, max_length=15)\n",
    "    print(f\"  '{example}' -> '{transformer_pred}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3545628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 8: Заключительные выводы\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ЗАКЛЮЧЕНИЕ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\"\"\n",
    "На основе проведенного сравнения можно сделать следующие выводы:\n",
    "\n",
    "1. **Качество генерации**:\n",
    "   - Transformer демонстрирует более связные и грамматически правильные продолжения\n",
    "   - LSTM показывает хорошие результаты на коротких последовательностях\n",
    "\n",
    "2. **Области применения**:\n",
    "   - Transformer лучше подходит для задач, требующих понимания контекста\n",
    "   - LSTM может быть предпочтительнее при ограниченных вычислительных ресурсах\n",
    "\n",
    "3. **Производительность**:\n",
    "   - Transformer требует значительных ресурсов для инференса\n",
    "   - LSTM работает быстрее и потребляет меньше памяти\n",
    "\n",
    "4. **Рекомендации**:\n",
    "   - Для высококачественной генерации: использовать Transformer\n",
    "   - Для embedded-систем или real-time приложений: рассмотреть LSTM\n",
    "   - Для специфических доменов: дообучить LSTM на целевых данных\n",
    "\n",
    "Проект успешно реализовал две различные архитектуры для автоматического дополнения текста\n",
    "и провел их сравнительный анализ по метрикам ROUGE и качеству генерации.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
