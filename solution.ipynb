{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6d00c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 1: Подготовка данных\n",
    "from src.data_utils import main as data_main\n",
    "data_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb6200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 2: Создание DataLoader'ов\n",
    "from src.next_token_dataset import create_data_loaders\n",
    "train_loader, val_loader, test_loader, vocab = create_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82ce36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 3: Обучение модели\n",
    "from src.lstm_train import train_model\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86994299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 4: Загрузка и тестирование обученной LSTM модели\n",
    "from src.lstm_model import LSTMLanguageModel\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTMLanguageModel(vocab_size=vocab['vocab_size']).to(device)\n",
    "\n",
    "# ИСПРАВЛЕННАЯ СТРОКА - добавьте map_location\n",
    "model.load_state_dict(torch.load('./models/lstm_model_bs64_accum4.pth', map_location=device))\n",
    "\n",
    "# Тестирование LSTM\n",
    "test_texts = [\"I think\", \"The weather is\", \"I want to\", \"This movie is\"]\n",
    "print(\"=== LSTM Model Predictions ===\")\n",
    "for test_text in test_texts:\n",
    "    prediction = model.predict_next_tokens(test_text, vocab, num_tokens=10)\n",
    "    print(f\"'{test_text}' -> '{prediction}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132b520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 5: Использование предобученного трансформера\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Использование предобученного трансформера\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "from src.transformer_model import TransformerTextGenerator, evaluate_transformer_model\n",
    "\n",
    "# Инициализация трансформера\n",
    "print(\"Загружаем модель distilgpt2...\")\n",
    "transformer_generator = TransformerTextGenerator()\n",
    "\n",
    "# Тестирование трансформера\n",
    "print(\"\\n=== Transformer Model Predictions ===\")\n",
    "for test_text in test_texts:\n",
    "    prediction = transformer_generator.generate_text(test_text, max_length=10)\n",
    "    print(f\"'{test_text}' -> '{prediction}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0063504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 6: Сравнение моделей по метрикам\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Сравнение моделей и выводы\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "from src.model_comparison import compare_models\n",
    "\n",
    "# Запускаем сравнение\n",
    "compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df06cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 7: Детальный анализ и выводы\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Финальные выводы и рекомендации\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Дополнительные примеры для качественного анализа\n",
    "print(\"\\nДополнительные примеры для сравнения:\")\n",
    "\n",
    "complex_examples = [\n",
    "    \"The future of artificial intelligence\",\n",
    "    \"I believe that climate change\",\n",
    "    \"The best way to learn programming\",\n",
    "    \"In my opinion, the government should\"\n",
    "]\n",
    "\n",
    "print(\"\\nLSTM Predictions:\")\n",
    "for example in complex_examples:\n",
    "    lstm_pred = model.predict_next_tokens(example, vocab, num_tokens=15)\n",
    "    print(f\"  '{example}' -> '{lstm_pred}'\")\n",
    "\n",
    "print(\"\\nTransformer Predictions:\")\n",
    "for example in complex_examples:\n",
    "    transformer_pred = transformer_generator.generate_text(example, max_length=15)\n",
    "    print(f\"  '{example}' -> '{transformer_pred}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3545628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ячейка 8: Заключительные выводы\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ЗАКЛЮЧЕНИЕ\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\"\"\n",
    "На основе проведенного сравнения можно сделать следующие выводы:\n",
    "\n",
    "1. **Качество генерации**:\n",
    "   - Transformer демонстрирует более связные и грамматически правильные продолжения.\n",
    "   - LSTM показывает хорошие результаты на коротких последовательностях. Однако текущего обучения недостаточно для хорошей генерации,\n",
    "       нужно увеличивать количество эпох или размер батча, для чего недостаточно вычислительных мощностей.\n",
    "\n",
    "2. **Области применения**:\n",
    "   - Transformer лучше подходит для задач, требующих понимания контекста\n",
    "   - LSTM может быть предпочтительнее при ограниченных вычислительных ресурсах, однако чтобы обучить ее с \n",
    "      нуля до какого-то приличного результата, тоже требуются большие вычислительные мощности.\n",
    "\n",
    "3. **Производительность**:\n",
    "   - Transformer требует значительных ресурсов для инференса\n",
    "   - LSTM работает быстрее и потребляет меньше памяти\n",
    "\n",
    "Проект успешно реализовал две различные архитектуры для автоматического дополнения текста\n",
    "и провел их сравнительный анализ по метрикам ROUGE и качеству генерации.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
